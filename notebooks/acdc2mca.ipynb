{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.general import *\n",
    "import utils.dataload as d\n",
    "from models import model_selector\n",
    "from utils.data_augmentation import data_augmentation_selector\n",
    "from medpy.metric.binary import hd, dc, jc, assd\n",
    "\n",
    "from utils.neural import *\n",
    "from utils.datasets import *\n",
    "from utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_path(directory, filename):\n",
    "    for path in Path(directory).rglob(filename):\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pred(image, pred_mask, case):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17, 10))\n",
    "    fig.tight_layout(pad=3)  # Set spacing between plots\n",
    "\n",
    "    ax1.imshow(image, cmap=\"gray\")\n",
    "    ax1.axis(\"off\")\n",
    "    ax1.set_title(\"Input Image\")\n",
    "\n",
    "    masked_lv = np.ma.masked_where(pred_mask == 0, pred_mask)\n",
    "    ax2.imshow(image, cmap=\"gray\")\n",
    "    ax2.imshow(masked_lv, 'hsv', interpolation='bilinear', alpha=0.33)\n",
    "    ax2.axis(\"off\")\n",
    "    ax2.set_title(\"Automatic Segmentation\")\n",
    "\n",
    "    fig.suptitle(case, y=0.9)\n",
    "    parent_dir = \"acdc2mca_preds_overlays\"\n",
    "    os.makedirs(parent_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(parent_dir, f\"{case}.jpg\"), dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Frosted pretrained backbone! ---\n",
      "Model total number of parameters: 36290058\n",
      "Loaded model from checkpoint: ../checks/acdc_model_resnet34_unet_imagenet_encoder_40epochs_swalr0.00256.pt\n"
     ]
    }
   ],
   "source": [
    "model = model_selector(\n",
    "    \"segmentation\", \"resnet34_unet_imagenet_encoder\", num_classes=4, from_swa=True,\n",
    "    in_channels=3, devices=[0], checkpoint=\"../checks/acdc_model_resnet34_unet_imagenet_encoder_40epochs_swalr0.00256.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LVSC 2D Segmentation Data Augmentation Combinations\n",
      "Padding masks!\n",
      "Padding masks!\n"
     ]
    }
   ],
   "source": [
    "_, _, val_aug = data_augmentation_selector(\n",
    "    \"acdc172d\", 224, 224, \"padd\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca_path = \"../data/MCA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca_volume_paths = [] \n",
    "for root, dirs, files in os.walk(mca_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".nii.gz\"):\n",
    "            filename = os.path.join(root, file)\n",
    "            mca_volume_paths.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c31579b59943fb95ac925877516ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "add_depth = True\n",
    "preds_dir = \"acdc2mca_preds\"\n",
    "os.makedirs(preds_dir, exist_ok=True)\n",
    "\n",
    "plot_preds = 100\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for volume_path in tqdm(mca_volume_paths):\n",
    "        volume, affine, header = d.load_nii(volume_path)  # [height, width, slices, phases]\n",
    "        original_volume = copy.deepcopy(volume)\n",
    "        h,w,_,_ = original_volume.shape\n",
    "        patient = volume_path.split(\"/\")[-1]\n",
    "        \n",
    "        full_mask = []\n",
    "        for c_phase in range(volume.shape[3]):\n",
    "            c_volume = volume[..., c_phase].transpose(2, 0, 1)\n",
    "\n",
    "            c_volume, _ = d.apply_volume_2Daugmentations(c_volume, val_aug, [])\n",
    "            c_volume = d.apply_normalization(c_volume, \"standardize\")\n",
    "\n",
    "            # We have to stack volume as batch\n",
    "            c_volume = np.expand_dims(c_volume, axis=0) if not add_depth else c_volume\n",
    "            c_volume = torch.from_numpy(c_volume)\n",
    "\n",
    "            if add_depth:\n",
    "                c_volume = d.add_volume_depth_channels(c_volume.unsqueeze(1))\n",
    "\n",
    "            vol_preds = model(c_volume)\n",
    "            \n",
    "            #pred_mask = reshape_volume(\n",
    "            #    torch.sigmoid(vol_preds).squeeze(1).data.cpu().numpy(), (h, w), \"padd\"\n",
    "            #)\n",
    "            #pred_mask = np.where(pred_mask > 0.5, 1, 0).astype(np.int32)\n",
    "            \n",
    "            pred_mask = convert_multiclass_mask(vol_preds).data.cpu().numpy()\n",
    "            pred_mask = reshape_volume(pred_mask, (h, w), \"padd\")\n",
    "            pred_mask = pred_mask.astype(np.uint8)\n",
    "            \n",
    "            full_mask.append(pred_mask)\n",
    "\n",
    "            for pred_indx, pred_slice in enumerate(pred_mask):\n",
    "                if plot_preds > 0:\n",
    "                    save_pred(\n",
    "                        original_volume[...,pred_indx, c_phase], pred_slice, \n",
    "                        f\"{patient[:-7]}_phase{c_phase}_slice{pred_indx}\"\n",
    "                    )\n",
    "                    plot_preds -= 1\n",
    "                    \n",
    "        full_mask = np.array(full_mask).transpose(2,3,1,0)\n",
    "        pred_name = f\"pred_{patient}\"\n",
    "        d.save_nii(os.path.join(preds_dir, pred_name), full_mask, affine, header)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
